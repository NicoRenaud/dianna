{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# Dash&Flask\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "from flask_caching import Cache\n",
    "# Onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx_tf.backend import prepare\n",
    "# Others\n",
    "import os\n",
    "import base64\n",
    "import layouts\n",
    "import utilities\n",
    "import numpy as np\n",
    "import dianna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind some folder on server for storing the data.\n",
    "folder_on_server = \"app_data\"\n",
    "os.makedirs(folder_on_server, exist_ok=True)\n",
    "\n",
    "# Build App\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets, prevent_initial_callbacks=True)\n",
    "\n",
    "# Caching\n",
    "cache = Cache(app.server, config={\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': 'cache'\n",
    "})\n",
    "cache.clear()\n",
    "\n",
    "# global variables\n",
    "class_name_mnist = ['digit 0', 'digit 1']\n",
    "#img_up = None\n",
    "#model_up = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/Users/giuliacrocioni/Desktop/eScience/projects_2022/DIANNA/dianna/dashboard/utilities.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "from importlib import reload\n",
    "reload(layouts)\n",
    "reload(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining: 100%|██████████| 50/50 [00:00<00:00, 64.91it/s]\n",
      "2022-04-05 00:26:55.510280: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-05 00:26:55.510426: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 00:26:57.673579: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-05 00:26:57.673648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/dash/dash.py\", line 1344, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/dash/_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"/var/folders/js/v54t24f101585t5fkkx3qpkh0000gn/T/ipykernel_34919/106893747.py\", line 170, in update_multi_options\n",
      "    output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx_tf/backend.py\", line 67, in prepare\n",
      "    super(TensorflowBackend, cls).prepare(model, device, **kwargs)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx/backend/base.py\", line 75, in prepare\n",
      "    onnx.checker.check_model(model)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx/checker.py\", line 105, in check_model\n",
      "    C.check_model(protobuf_string)\n",
      "onnx.onnx_cpp2py_export.checker.ValidationError: The model does not have an ir_version set properly.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1391, in handle_user_exception\n",
      "    return self.ensure_sync(handler)(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py\", line 364, in _wrap_errors\n",
      "    tb_werkzeug = DebugTraceback()\n",
      "TypeError: __init__() missing 1 required positional argument: 'exc'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/werkzeug/serving.py\", line 319, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/werkzeug/serving.py\", line 306, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2095, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2080, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1438, in handle_exception\n",
      "    server_error = self.ensure_sync(handler)(server_error)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py\", line 364, in _wrap_errors\n",
      "    tb_werkzeug = DebugTraceback()\n",
      "TypeError: __init__() missing 1 required positional argument: 'exc'\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/dash/dash.py\", line 1344, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/dash/_callback.py\", line 151, in add_context\n",
      "    output_value = func(*func_args, **func_kwargs)  # %% callback invoked %%\n",
      "  File \"/var/folders/js/v54t24f101585t5fkkx3qpkh0000gn/T/ipykernel_34919/106893747.py\", line 170, in update_multi_options\n",
      "    output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx_tf/backend.py\", line 67, in prepare\n",
      "    super(TensorflowBackend, cls).prepare(model, device, **kwargs)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx/backend/base.py\", line 75, in prepare\n",
      "    onnx.checker.check_model(model)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/onnx/checker.py\", line 105, in check_model\n",
      "    C.check_model(protobuf_string)\n",
      "onnx.onnx_cpp2py_export.checker.ValidationError: The model does not have an ir_version set properly.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1391, in handle_user_exception\n",
      "    return self.ensure_sync(handler)(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py\", line 364, in _wrap_errors\n",
      "    tb_werkzeug = DebugTraceback()\n",
      "TypeError: __init__() missing 1 required positional argument: 'exc'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/werkzeug/serving.py\", line 319, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/werkzeug/serving.py\", line 306, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2095, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 2080, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/flask/app.py\", line 1438, in handle_exception\n",
      "    server_error = self.ensure_sync(handler)(server_error)\n",
      "  File \"/Users/giuliacrocioni/miniforge3/envs/dianna_new/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py\", line 364, in _wrap_errors\n",
      "    tb_werkzeug = DebugTraceback()\n",
      "TypeError: __init__() missing 1 required positional argument: 'exc'\n"
     ]
    }
   ],
   "source": [
    "app.layout = html.Div([\n",
    "    \n",
    "    #Row 1 : Header\n",
    "    layouts.get_header(),\n",
    "    #Row 2 : Nav bar\n",
    "    layouts.get_navbar(),\n",
    "\n",
    "    layouts.get_uploads(),\n",
    "\n",
    "    # hidden signal value\n",
    "    dcc.Store(id='signal'),\n",
    "    \n",
    "    ])\n",
    "\n",
    "@app.callback(Output('output-model-upload', 'children'),\n",
    "              Input('upload-model', 'contents'),\n",
    "              State('upload-model', 'filename'))\n",
    "def upload_model(contents, filename):\n",
    "    if contents is not None:\n",
    "        try:\n",
    "            if 'onnx' in filename[0]:\n",
    "\n",
    "                content_type, content_string = contents[0].split(',')\n",
    "\n",
    "                with open(os.path.join(folder_on_server, filename[0]), 'wb') as f:\n",
    "                    f.write(base64.b64decode(content_string))\n",
    "\n",
    "                return html.Div([f'{filename[0]} uploaded'])\n",
    "            else:\n",
    "                return html.Div([\n",
    "                    html.P('File format error!'),\n",
    "                    html.Br(),\n",
    "                    html.P('Please upload only models in .onnx format.')\n",
    "                    ])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return html.Div(['There was an error processing this file.'])\n",
    "    else:\n",
    "        raise PreventUpdate\n",
    "\n",
    "@app.callback(Output('graph_test', 'figure'),\n",
    "              Input('upload-image', 'contents'),\n",
    "              State('upload-image', 'filename'))\n",
    "def upload_image(contents, filename):\n",
    "    if contents is not None:\n",
    "\n",
    "        try:\n",
    "\n",
    "            if 'jpg' in filename[0]:\n",
    "\n",
    "                content_type, content_string = contents[0].split(',')\n",
    "\n",
    "                with open(os.path.join(folder_on_server, filename[0]), 'wb') as f:\n",
    "                    f.write(base64.b64decode(content_string))\n",
    "\n",
    "                data_path = os.path.join(folder_on_server, filename[0])\n",
    "\n",
    "                X_test = utilities.open_image(data_path)\n",
    "\n",
    "                fig = go.Figure()\n",
    "\n",
    "                if X_test.shape[2] < 3: # it's grayscale\n",
    "\n",
    "                    fig.add_trace(go.Heatmap(z=X_test[:,:,0], colorscale='gray', showscale=False))\n",
    "\n",
    "                fig.update_layout(\n",
    "                    width=300,\n",
    "                    height=300,\n",
    "                    title=f\"{filename[0]} uploaded\",\n",
    "                    title_x=0.5,\n",
    "                    title_font_color=layouts.colors['blue1'])\n",
    "\n",
    "                fig.update_xaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "                fig.update_yaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "\n",
    "                fig.layout.paper_bgcolor = layouts.colors['blue4']\n",
    "\n",
    "                return fig\n",
    "            else:\n",
    "                return utilities.blank_fig(\n",
    "                    text='File format error! <br><br>Please upload only images in .jpg format.')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return utilities.blank_fig(\n",
    "                    text='There was an error processing this file.')\n",
    "\n",
    "# perform expensive computations in this \"global store\"\n",
    "# these computations are cached in a globally available\n",
    "# redis memory store which is available across processes\n",
    "# and for all time.\n",
    "@cache.memoize()\n",
    "def global_store(method_sel, model_path, image_test):\n",
    "    # expensive query\n",
    "    if method_sel == \"RISE\":\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test, method=method_sel,\n",
    "            labels=[i for i in range(2)],\n",
    "            n_masks=5000, feature_res=8, p_keep=.1,\n",
    "            axis_labels=('height','width','channels'))\n",
    "\n",
    "    elif method_sel == \"KernelSHAP\":\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test,\n",
    "            method=method_sel, nsamples=1000,\n",
    "            background=0, n_segments=200, sigma=0,\n",
    "            axis_labels=('height','width','channels'))\n",
    "\n",
    "    else:\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test * 256, 'LIME',\n",
    "            axis_labels=('height','width','channels'),\n",
    "            random_state=2,\n",
    "            labels=[i for i in range(2)],\n",
    "            preprocess_function=utilities.preprocess_function)\n",
    "\n",
    "    return relevances\n",
    "\n",
    "@app.callback(\n",
    "    Output('signal', 'data'),\n",
    "    [Input('method_sel', 'value'),\n",
    "    State(\"upload-model\", \"filename\"),\n",
    "    State(\"upload-image\", \"filename\"),\n",
    "    ])\n",
    "def compute_value(method_sel, fn_m, fn_i):\n",
    "\n",
    "    if method_sel is None:\n",
    "        raise PreventUpdate\n",
    "    else:\n",
    "        for m in method_sel:\n",
    "            # compute value and send a signal when done\n",
    "            data_path = os.path.join(folder_on_server, fn_i[0])\n",
    "            image_test = utilities.open_image(data_path)\n",
    "\n",
    "            model_path = os.path.join(folder_on_server, fn_m[0])\n",
    "\n",
    "            try:\n",
    "                global_store(m, model_path, image_test)\n",
    "            except Exception:\n",
    "                return method_sel\n",
    "                \n",
    "        return method_sel\n",
    "\n",
    "@app.callback(\n",
    "    Output('output-state', 'children'),\n",
    "    Output('graph', 'figure'),\n",
    "    Input(\"signal\", \"data\"),\n",
    "    State(\"upload-model\", \"filename\"),\n",
    "    State(\"upload-image\", \"filename\"),\n",
    "    Input(\"upload-model\", \"filename\"),\n",
    ")\n",
    "def update_multi_options(sel_methods, fn_m, fn_i, new_model):\n",
    "\n",
    "    ctx = dash.callback_context\n",
    "\n",
    "    if (ctx.triggered[0][\"prop_id\"] == \"upload-model.filename\") or (not ctx.triggered):\n",
    "        cache.clear()\n",
    "        return html.Div(['']), utilities.blank_fig()\n",
    "    elif (not sel_methods):\n",
    "        return html.Div(['']), utilities.blank_fig()\n",
    "    else:\n",
    "        # update graph\n",
    "        if (fn_m and fn_i) is not None:\n",
    "\n",
    "            data_path = os.path.join(folder_on_server, fn_i[0])\n",
    "            X_test = utilities.open_image(data_path)\n",
    "\n",
    "            onnx_model_path = os.path.join(folder_on_server, fn_m[0])\n",
    "            onnx_model = onnx.load(onnx_model_path)\n",
    "            # get the output node\n",
    "            output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]\n",
    "\n",
    "            try:\n",
    "                predictions = prepare(onnx_model).run(X_test[None, ...])[f'{output_node}']\n",
    "\n",
    "                if len(predictions[0]) == 2:\n",
    "                    class_name = [c for c in class_name_mnist]\n",
    "\n",
    "                pred_class = class_name[np.argmax(predictions)]\n",
    "\n",
    "                n_rows = len(class_name)\n",
    "\n",
    "                fig = make_subplots(rows=n_rows, cols=3, subplot_titles=(\"RISE\", \"KernelShap\", \"LIME\"))#, horizontal_spacing = 0.05)\n",
    "\n",
    "                for m in sel_methods:\n",
    "\n",
    "                    for i in range(n_rows):\n",
    "\n",
    "                        fig.update_yaxes(title_text=class_name[i], row=i+1, col=1)\n",
    "\n",
    "                        if m == \"RISE\":\n",
    "                            \n",
    "                            try:\n",
    "                                relevances_rise = global_store(\n",
    "                                    m, onnx_model_path, X_test)\n",
    "\n",
    "                                # RISE plot\n",
    "                                fig.add_trace(go.Heatmap(\n",
    "                                                    z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 1)\n",
    "                                fig.add_trace(go.Heatmap(\n",
    "                                                    z=relevances_rise[i], colorscale='Bluered',\n",
    "                                                    showscale=False, opacity=0.7), i+1, 1)\n",
    "\n",
    "                            except Exception:\n",
    "                                html.Div(['There was an error running the model. Check either the test image or the model.']), utilities.blank_fig()\n",
    "\n",
    "                        elif m == \"KernelSHAP\":\n",
    "\n",
    "                            shap_values, segments_slic = global_store(\n",
    "                                m, onnx_model_path, X_test)\n",
    "\n",
    "                            # KernelSHAP plot\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                            z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 2)\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                            z=utilities.fill_segmentation(shap_values[i][0], segments_slic),\n",
    "                                            colorscale='Bluered',\n",
    "                                            showscale=False,\n",
    "                                            opacity=0.7), i+1, 2)\n",
    "                        else:\n",
    "\n",
    "                            relevances_lime = global_store(\n",
    "                                m, onnx_model_path, X_test)\n",
    "\n",
    "                            # LIME plot\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 3)\n",
    "\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=relevances_lime[i], colorscale='Bluered',\n",
    "                                                showscale=False, opacity=0.7), i+1, 3)\n",
    "\n",
    "                fig.update_layout(\n",
    "                    width=650,\n",
    "                    height=500,\n",
    "                    paper_bgcolor=layouts.colors['blue4'])\n",
    "\n",
    "                fig.update_xaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "                fig.update_yaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "\n",
    "                return html.Div(['The predicted class is: ' + pred_class], style = {\n",
    "                    'fontSize': 14,\n",
    "                    'margin-top': '20px',\n",
    "                    'margin-right': '40px'\n",
    "                    }), fig\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return html.Div(['There was an error running the model. Check either the test image or the model.']), utilities.blank_fig()\n",
    "        else:\n",
    "            return html.Div(['Missing either model or image.']), utilities.blank_fig()\n",
    "\n",
    "app.run_server(mode='external', port=8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1169365229a6973d4396a155ae30c4ccccac7e32d4a33e84a8e817391c6ab2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dianna_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
