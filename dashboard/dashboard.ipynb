{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# Dash&Flask\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.exceptions import PreventUpdate\n",
    "from flask_caching import Cache\n",
    "# Onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx_tf.backend import prepare\n",
    "# Others\n",
    "import os\n",
    "import base64\n",
    "import layouts\n",
    "import utilities\n",
    "import numpy as np\n",
    "import dianna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind some folder on server for storing the data.\n",
    "folder_on_server = \"app_data\"\n",
    "os.makedirs(folder_on_server, exist_ok=True)\n",
    "\n",
    "# Build App\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets, prevent_initial_callbacks=True)\n",
    "\n",
    "# Caching\n",
    "cache = Cache(app.server, config={\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': 'cache'\n",
    "})\n",
    "cache.clear()\n",
    "\n",
    "# global variables\n",
    "class_name_mnist = ['digit 0', 'digit 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/Users/giuliacrocioni/Desktop/eScience/projects_2022/DIANNA/dianna/dashboard/utilities.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "from importlib import reload\n",
    "reload(layouts)\n",
    "reload(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining: 100%|██████████| 50/50 [00:00<00:00, 64.25it/s]\n",
      "2022-04-04 19:40:44.397488: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-04 19:40:44.397611: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 19:40:46.579636: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-04 19:40:46.579699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:40:54.522721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]2022-04-04 19:40:54.723249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:40:55.372941: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function BackendTFModule.__call__ at 0x2cd992ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 19:40:56.366216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 5000/5000 [00:02<00:00, 1837.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function BackendTFModule.__call__ at 0x2cc569790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 19:41:05.434760: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:18.054361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:23.102612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:28.236256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:28.902914: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:29.640999: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-04 19:41:37.074125: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "app.layout = html.Div([\n",
    "    \n",
    "    #Row 1 : Header\n",
    "    layouts.get_header(),\n",
    "    #Row 2 : Nav bar\n",
    "    layouts.get_navbar(),\n",
    "\n",
    "    layouts.get_uploads(),\n",
    "\n",
    "    # hidden signal value\n",
    "    dcc.Store(id='signal'),\n",
    "    \n",
    "    ])\n",
    "\n",
    "@app.callback(Output('output-model-upload', 'children'),\n",
    "              Input('upload-model', 'contents'),\n",
    "              State('upload-model', 'filename'))\n",
    "def upload_model(contents, filename):\n",
    "    if contents is not None:\n",
    "        try:\n",
    "            if 'onnx' in filename[0]:\n",
    "\n",
    "                content_type, content_string = contents[0].split(',')\n",
    "\n",
    "                with open(os.path.join(folder_on_server, filename[0]), 'wb') as f:\n",
    "                    f.write(base64.b64decode(content_string))\n",
    "\n",
    "                children = [\n",
    "                    utilities.parse_contents_model(c, n) for c, n in\n",
    "                    zip(contents, filename)]\n",
    "\n",
    "                return children\n",
    "            else:\n",
    "                return html.Div([\n",
    "                    html.P('File format error!'),\n",
    "                    html.Br(),\n",
    "                    html.P('Please upload only models in .onnx format.')\n",
    "                    ])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return html.Div(['There was an error processing this file.'])\n",
    "    else:\n",
    "        raise PreventUpdate\n",
    "\n",
    "@app.callback(Output('graph_test', 'figure'), \n",
    "              Input('upload-image', 'contents'),\n",
    "              State('upload-image', 'filename'))\n",
    "def upload_image(contents, filename):\n",
    "    if contents is not None:\n",
    "\n",
    "        try:\n",
    "\n",
    "            if 'jpg' in filename[0]:\n",
    "\n",
    "                content_type, content_string = contents[0].split(',')\n",
    "\n",
    "                with open(os.path.join(folder_on_server, filename[0]), 'wb') as f:\n",
    "                    f.write(base64.b64decode(content_string))\n",
    "\n",
    "                data_path = os.path.join(folder_on_server, filename[0])\n",
    "\n",
    "                X_test = utilities.open_image(data_path)\n",
    "\n",
    "                fig = go.Figure()\n",
    "\n",
    "                if X_test.shape[2] < 3: # it's grayscale\n",
    "\n",
    "                    fig.add_trace(go.Heatmap(z=X_test[:,:,0], colorscale='gray', showscale=False))\n",
    "\n",
    "                fig.update_layout(\n",
    "                    width=300,\n",
    "                    height=300,\n",
    "                    title=f\"{filename[0]} uploaded\",\n",
    "                    title_x=0.5,\n",
    "                    title_font_color=layouts.colors['blue1'])\n",
    "\n",
    "                fig.update_xaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "                fig.update_yaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "\n",
    "                fig.layout.paper_bgcolor = layouts.colors['blue4']\n",
    "\n",
    "                return fig\n",
    "            else:\n",
    "                return utilities.blank_fig(\n",
    "                    text='File format error! <br><br>Please upload only images in .jpg format.')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return utilities.blank_fig(\n",
    "                    text='There was an error processing this file.')\n",
    "\n",
    "# perform expensive computations in this \"global store\"\n",
    "# these computations are cached in a globally available\n",
    "# redis memory store which is available across processes\n",
    "# and for all time.\n",
    "@cache.memoize()\n",
    "def global_store(method_sel, model_path, image_test):\n",
    "    # expensive query\n",
    "    if method_sel == \"RISE\":\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test, method=method_sel,\n",
    "            labels=[i for i in range(2)],\n",
    "            n_masks=5000, feature_res=8, p_keep=.1,\n",
    "            axis_labels=('height','width','channels'))\n",
    "\n",
    "    elif method_sel == \"KernelSHAP\":\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test,\n",
    "            method=method_sel, nsamples=1000,\n",
    "            background=0, n_segments=200, sigma=0,\n",
    "            axis_labels=('height','width','channels'))\n",
    "\n",
    "    else:\n",
    "        relevances = dianna.explain_image(\n",
    "            model_path, image_test * 256, 'LIME',\n",
    "            axis_labels=('height','width','channels'),\n",
    "            random_state=2,\n",
    "            labels=[i for i in range(2)],\n",
    "            preprocess_function=utilities.preprocess_function)\n",
    "\n",
    "    return relevances\n",
    "\n",
    "@app.callback(\n",
    "    Output('signal', 'data'),\n",
    "    [Input('method_sel', 'value'),\n",
    "    State(\"upload-model\", \"filename\"),\n",
    "    State(\"upload-image\", \"filename\"),\n",
    "    ])\n",
    "def compute_value(method_sel, fn_m, fn_i):\n",
    "    if method_sel is None:\n",
    "        raise PreventUpdate\n",
    "    else:\n",
    "        for m in method_sel:\n",
    "            # compute value and send a signal when done\n",
    "            data_path = os.path.join(folder_on_server, fn_i[0])\n",
    "            image_test = utilities.open_image(data_path)\n",
    "\n",
    "            model_path = os.path.join(folder_on_server, fn_m[0])\n",
    "\n",
    "            global_store(m, model_path, image_test)\n",
    "        return method_sel\n",
    "\n",
    "@app.callback(\n",
    "    Output('output-state', 'children'),\n",
    "    Output('graph', 'figure'),\n",
    "    Input(\"signal\", \"data\"),\n",
    "    State(\"upload-model\", \"filename\"),\n",
    "    State(\"upload-image\", \"filename\"),\n",
    ")\n",
    "def update_multi_options(sel_methods, fn_m, fn_i):\n",
    "    if sel_methods is None:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    else:\n",
    "\n",
    "        if (fn_m and fn_i) is not None:\n",
    "\n",
    "            try:\n",
    "\n",
    "                data_path = os.path.join(folder_on_server, fn_i[0])\n",
    "                X_test = utilities.open_image(data_path)\n",
    "\n",
    "                onnx_model_path = os.path.join(folder_on_server, fn_m[0])\n",
    "                onnx_model = onnx.load(onnx_model_path)\n",
    "                # get the output node\n",
    "                output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]\n",
    "                predictions = prepare(onnx_model).run(X_test[None, ...])[f'{output_node}']\n",
    "\n",
    "                if len(predictions[0]) == 2:\n",
    "                    class_name = [c for c in class_name_mnist]\n",
    "\n",
    "                pred_class = class_name[np.argmax(predictions)]\n",
    "\n",
    "                n_rows = len(class_name)\n",
    "\n",
    "                fig = make_subplots(rows=n_rows, cols=3, subplot_titles=(\"RISE\", \"KernelShap\", \"LIME\"))#, horizontal_spacing = 0.05)\n",
    "\n",
    "                for m in sel_methods:\n",
    "\n",
    "                    for i in range(n_rows):\n",
    "\n",
    "                        fig.update_yaxes(title_text=class_name[i], row=i+1, col=1)\n",
    "\n",
    "                        if m == \"RISE\":\n",
    "\n",
    "                            relevances_rise = global_store(\n",
    "                                m, onnx_model_path, X_test)\n",
    "\n",
    "                            # RISE plot\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 1)\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=relevances_rise[i], colorscale='Bluered',\n",
    "                                                showscale=False, opacity=0.7), i+1, 1)\n",
    "\n",
    "                        elif m == \"KernelSHAP\":\n",
    "\n",
    "                            shap_values, segments_slic = global_store(\n",
    "                                m, onnx_model_path, X_test)\n",
    "\n",
    "                            # KernelSHAP plot\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                            z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 2)\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                            z=utilities.fill_segmentation(shap_values[i][0], segments_slic),\n",
    "                                            colorscale='Bluered',\n",
    "                                            showscale=False,\n",
    "                                            opacity=0.7), i+1, 2)\n",
    "                        else:\n",
    "\n",
    "                            relevances_lime = global_store(\n",
    "                                m, onnx_model_path, X_test)\n",
    "\n",
    "                            # LIME plot\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=X_test[:,:,0], colorscale='gray', showscale=False), i+1, 3)\n",
    "\n",
    "                            fig.add_trace(go.Heatmap(\n",
    "                                                z=relevances_lime[i], colorscale='Bluered',\n",
    "                                                showscale=False, opacity=0.7), i+1, 3)\n",
    "\n",
    "                fig.update_layout(\n",
    "                    width=650,\n",
    "                    height=500,\n",
    "                    paper_bgcolor=layouts.colors['blue4'])\n",
    "\n",
    "                fig.update_xaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "                fig.update_yaxes(showgrid = False, showticklabels = False, zeroline=False)\n",
    "\n",
    "                return html.Div(['The predicted class is: ' + pred_class], style = {\n",
    "                    'fontSize': 14,\n",
    "                    'margin-top': '20px',\n",
    "                    'margin-right': '40px'\n",
    "                    }), fig\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                return html.Div(['There was an error running the model. Check either the test image or the model.']), None\n",
    "        else:\n",
    "            return html.Div(['Missing either model or image.']), None\n",
    "\n",
    "app.run_server(mode='external', port=8050)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1169365229a6973d4396a155ae30c4ccccac7e32d4a33e84a8e817391c6ab2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dianna_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
