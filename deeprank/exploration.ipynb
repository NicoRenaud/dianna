{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "# from deeprankCore.Data import save_hdf5_keys\n",
    "import torch\n",
    "from models import CnnClassificationBaseline\n",
    "from deeprank.learn import DataSet, NeuralNet\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from deeprankcore.Dataset to avoid having to install that\n",
    "\n",
    "def save_hdf5_keys(\n",
    "    f_src_path: str,\n",
    "    src_ids: List[str],\n",
    "    f_dest_path: str,\n",
    "    hardcopy = False\n",
    "    ):\n",
    "    \"\"\"Save references to keys in data_ids in a new hdf5 file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f_src_path : str\n",
    "        The path to the hdf5 file containing the keys.\n",
    "    src_ids : List[str]\n",
    "        Keys to be saved in the new hdf5 file.\n",
    "        It should be a list containing at least one key.\n",
    "    f_dest_path : str\n",
    "        The path to the new hdf5 file.\n",
    "    hardcopy : bool, default = False\n",
    "        If False, the new file contains only references.\n",
    "        (external links, see h5py ExternalLink class) to the original hdf5 file.\n",
    "        If True, the new file contains a copy of the objects specified in data_ids\n",
    "        (see h5py HardLink class).\n",
    "        \n",
    "    \"\"\"\n",
    "    if not all(isinstance(d, str) for d in src_ids):\n",
    "        raise TypeError(\"data_ids should be a list containing strings.\")\n",
    "\n",
    "    with h5py.File(f_dest_path,'w') as f_dest, h5py.File(f_src_path,'r') as f_src:\n",
    "        for key in src_ids:\n",
    "            if hardcopy:\n",
    "                f_src.copy(f_src[key],f_dest)\n",
    "            else:\n",
    "                f_dest[key] = h5py.ExternalLink(f_src_path, \"/\" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/aronjansen/Documents/deeprankData/'\n",
    "hdf5_path = DATA_PATH + '000_hla_drb1_0101_15mers.hdf5'\n",
    "sample_path = DATA_PATH + 'one_sample.hdf5'\n",
    "pretrained_model = 'best_valid_model.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hdf5_keys(hdf5_path, ['BA_105966'], sample_path, hardcopy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = h5py.File(sample_path, 'r')\n",
    "print(tst['BA_105966'].keys())\n",
    "print(tst['BA_105966']['features_raw'].keys())\n",
    "tst['BA_105966']['features']['PSSM_ARG'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(sample_path, CnnClassificationBaseline, pretrained_model = pretrained_model, outdir='./out/')\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.data_set.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step without using NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = DataSet(\n",
    "    sample_path,\n",
    "    chain1=\"M\",\n",
    "    chain2=\"P\",\n",
    "    process=False)\n",
    "\n",
    "state = torch.load(pretrained_model,  map_location='cpu')\n",
    "\n",
    "data_set.select_feature = state['select_feature']\n",
    "data_set.select_target = state['select_target']\n",
    "\n",
    "data_set.pair_chain_feature = state['pair_chain_feature']\n",
    "data_set.dict_filter = state['dict_filter']\n",
    "\n",
    "data_set.normalize_targets = state['normalize_targets']\n",
    "if data_set.normalize_targets:\n",
    "    data_set.target_min = state['target_min']\n",
    "    data_set.target_max = state['target_max']\n",
    "\n",
    "data_set.normalize_features = state['normalize_features']\n",
    "if data_set.normalize_features:\n",
    "    data_set.feature_mean = state['feature_mean']\n",
    "    data_set.feature_std = state['feature_std']\n",
    "\n",
    "data_set.transform = state['transform']\n",
    "data_set.proj2D = state['proj2D']\n",
    "data_set.target_ordering = state['target_ordering']\n",
    "data_set.clip_features = state['clip_features']\n",
    "data_set.clip_factor = state['clip_factor']\n",
    "data_set.mapfly = state['mapfly']\n",
    "data_set.grid_info = state['grid_info']\n",
    "\n",
    "data_set.process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CnnClassificationBaseline(data_set.input_shape)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "if state['cuda']:\n",
    "    for paramname in list(state['state_dict'].keys()):\n",
    "        paramname_new = paramname.lstrip('module.')\n",
    "        if paramname != paramname_new:\n",
    "            state['state_dict'][paramname_new] = \\\n",
    "                state['state_dict'][paramname]\n",
    "            del state['state_dict'][paramname]\n",
    "\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.001)\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(data_set.__len__()))\n",
    "sampler = data_utils.sampler.SubsetRandomSampler(index)\n",
    "loader = data_utils.DataLoader(data_set, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(loader):\n",
    "    print(data['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(mode=False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in loader:\n",
    "    inputs = d['feature']\n",
    "    targets = d['target']\n",
    "    mol = d['mol']\n",
    "    inputs, targets = Variable(inputs).float(), Variable(targets).float()\n",
    "    targets = targets.long()\n",
    "    print(mol)\n",
    "    print(inputs.shape)\n",
    "    print(targets)\n",
    "    outputs = net(inputs)\n",
    "    print(outputs)\n",
    "    targets = targets.view(-1)\n",
    "    print(targets)\n",
    "    # F.softmax(torch.FloatTensor(out), dim=1).data.numpy()[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_toplot = np.squeeze(np.array(inputs))\n",
    "inputs_toplot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_vol = inputs_toplot[0, :, :, :]\n",
    "one_vol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dianna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46ac0e5d3095c4497c061181ea9054f5ea4f47ef5144a77a8361c63aca65eec5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
