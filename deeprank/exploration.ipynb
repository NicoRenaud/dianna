{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from deeprankcore.DataSet import save_hdf5_keys\n",
    "import torch\n",
    "from models import CnnClassificationBaseline\n",
    "from deeprank.learn import DataSet, NeuralNet\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = '000_hla_drb1_0101_15mers.hdf5'\n",
    "sample_path = 'one_sample.hdf5'\n",
    "pretrained_model = 'best_valid_model.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hdf5_keys(hdf5_path, ['BA_105966'], sample_path, hardcopy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "=\t DeepRank Data Set\n",
      "=\n",
      "=\t Training data\n",
      "=\t -> one_sample.hdf5\n",
      "=\n",
      "=\n",
      "=\n",
      "========================================\n",
      "\n",
      "   Checking dataset Integrity\n",
      "\n",
      "\n",
      "   Processing data set:\n",
      "   Train dataset\n",
      "      Computing norm for one_sample.hdf5\n",
      " : STD is null for PSSM_ARG_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_CYS_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_GLN_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_GLU_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_HIS_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_ILE_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_MET_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_PHE_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_PRO_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_TRP_chain2 in one_sample.hdf5\n",
      "  Final STD Null for Feature_ind/PSSM_ARG_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_CYS_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_GLN_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_GLU_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_HIS_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_ILE_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_MET_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_PHE_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_PRO_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_TRP_chain2. Changed it to 1\n",
      "\n",
      "\n",
      "   Data Set Info:\n",
      "   Augmentation       : 0 rotations\n",
      "   Training set       : 1 conformations\n",
      "   Validation set     : 0 conformations\n",
      "   Test set           : 0 conformations\n",
      "   Number of channels : 64\n",
      "   Grid Size          : 35, 30, 30\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm3d-1       [-1, 64, 35, 30, 30]             128\n",
      "            Conv3d-2       [-1, 64, 34, 29, 29]          32,832\n",
      "              ReLU-3       [-1, 64, 34, 29, 29]               0\n",
      "         MaxPool3d-4       [-1, 64, 17, 14, 14]               0\n",
      "            Conv3d-5      [-1, 128, 16, 13, 13]          65,664\n",
      "              ReLU-6      [-1, 128, 16, 13, 13]               0\n",
      "         MaxPool3d-7         [-1, 128, 8, 6, 6]               0\n",
      "            Conv3d-8         [-1, 192, 7, 5, 5]         196,800\n",
      "              ReLU-9         [-1, 192, 7, 5, 5]               0\n",
      "        MaxPool3d-10         [-1, 192, 3, 2, 2]               0\n",
      "          Flatten-11                 [-1, 2304]               0\n",
      "      BatchNorm1d-12                 [-1, 2304]           4,608\n",
      "           Linear-13                 [-1, 1000]       2,305,000\n",
      "             ReLU-14                 [-1, 1000]               0\n",
      "          Dropout-15                 [-1, 1000]               0\n",
      "           Linear-16                 [-1, 1000]       1,001,000\n",
      "             ReLU-17                 [-1, 1000]               0\n",
      "          Dropout-18                 [-1, 1000]               0\n",
      "           Linear-19                    [-1, 2]           2,002\n",
      "================================================================\n",
      "Total params: 3,608,034\n",
      "Trainable params: 3,608,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7.69\n",
      "Forward/backward pass size (MB): 51.11\n",
      "Params size (MB): 13.76\n",
      "Estimated Total Size (MB): 72.56\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "========================================\n",
      "=\t Convolution Neural Network\n",
      "=\t model   : 3d\n",
      "=\t CNN      : CnnClassificationBaseline\n",
      "=\t features : Feature_ind\n",
      "=\t\t     Edesolv_chain1\n",
      "=\t\t     Edesolv_chain2\n",
      "=\t\t     PSSM_ALA_chain1\n",
      "=\t\t     PSSM_ALA_chain2\n",
      "=\t\t     PSSM_ARG_chain1\n",
      "=\t\t     PSSM_ARG_chain2\n",
      "=\t\t     PSSM_ASN_chain1\n",
      "=\t\t     PSSM_ASN_chain2\n",
      "=\t\t     PSSM_ASP_chain1\n",
      "=\t\t     PSSM_ASP_chain2\n",
      "=\t\t     PSSM_CYS_chain1\n",
      "=\t\t     PSSM_CYS_chain2\n",
      "=\t\t     PSSM_GLN_chain1\n",
      "=\t\t     PSSM_GLN_chain2\n",
      "=\t\t     PSSM_GLU_chain1\n",
      "=\t\t     PSSM_GLU_chain2\n",
      "=\t\t     PSSM_GLY_chain1\n",
      "=\t\t     PSSM_GLY_chain2\n",
      "=\t\t     PSSM_HIS_chain1\n",
      "=\t\t     PSSM_HIS_chain2\n",
      "=\t\t     PSSM_ILE_chain1\n",
      "=\t\t     PSSM_ILE_chain2\n",
      "=\t\t     PSSM_LEU_chain1\n",
      "=\t\t     PSSM_LEU_chain2\n",
      "=\t\t     PSSM_LYS_chain1\n",
      "=\t\t     PSSM_LYS_chain2\n",
      "=\t\t     PSSM_MET_chain1\n",
      "=\t\t     PSSM_MET_chain2\n",
      "=\t\t     PSSM_PHE_chain1\n",
      "=\t\t     PSSM_PHE_chain2\n",
      "=\t\t     PSSM_PRO_chain1\n",
      "=\t\t     PSSM_PRO_chain2\n",
      "=\t\t     PSSM_SER_chain1\n",
      "=\t\t     PSSM_SER_chain2\n",
      "=\t\t     PSSM_THR_chain1\n",
      "=\t\t     PSSM_THR_chain2\n",
      "=\t\t     PSSM_TRP_chain1\n",
      "=\t\t     PSSM_TRP_chain2\n",
      "=\t\t     PSSM_TYR_chain1\n",
      "=\t\t     PSSM_TYR_chain2\n",
      "=\t\t     PSSM_VAL_chain1\n",
      "=\t\t     PSSM_VAL_chain2\n",
      "=\t\t     RCD_apolar-apolar_chain1\n",
      "=\t\t     RCD_apolar-apolar_chain2\n",
      "=\t\t     RCD_apolar-charged_chain1\n",
      "=\t\t     RCD_apolar-charged_chain2\n",
      "=\t\t     RCD_charged-charged_chain1\n",
      "=\t\t     RCD_charged-charged_chain2\n",
      "=\t\t     RCD_polar-apolar_chain1\n",
      "=\t\t     RCD_polar-apolar_chain2\n",
      "=\t\t     RCD_polar-charged_chain1\n",
      "=\t\t     RCD_polar-charged_chain2\n",
      "=\t\t     RCD_polar-polar_chain1\n",
      "=\t\t     RCD_polar-polar_chain2\n",
      "=\t\t     RCD_total_chain1\n",
      "=\t\t     RCD_total_chain2\n",
      "=\t\t     bsa_chain1\n",
      "=\t\t     bsa_chain2\n",
      "=\t\t     charge_chain1\n",
      "=\t\t     charge_chain2\n",
      "=\t\t     coulomb_chain1\n",
      "=\t\t     coulomb_chain2\n",
      "=\t\t     vdwaals_chain1\n",
      "=\t\t     vdwaals_chain2\n",
      "=\t targets  : BIN_CLASS\n",
      "=\t CUDA     : False\n",
      "========================================\n",
      "\n",
      "\t\t-> mini-batch: 1 \n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(sample_path, CnnClassificationBaseline, pretrained_model = pretrained_model, outdir='./out/')\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 35, 30, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.data_set.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step without using NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================\n",
      "=\t DeepRank Data Set\n",
      "=\n",
      "=\t Training data\n",
      "=\t -> one_sample.hdf5\n",
      "=\n",
      "=\n",
      "=\n",
      "========================================\n",
      "\n",
      "   Checking dataset Integrity\n",
      "\n",
      "\n",
      "   Processing data set:\n",
      "   Train dataset\n",
      " : STD is null for PSSM_ARG_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_CYS_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_GLN_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_GLU_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_HIS_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_ILE_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_MET_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_PHE_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_PRO_chain2 in one_sample.hdf5\n",
      " : STD is null for PSSM_TRP_chain2 in one_sample.hdf5\n",
      "  Final STD Null for Feature_ind/PSSM_ARG_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_CYS_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_GLN_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_GLU_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_HIS_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_ILE_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_MET_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_PHE_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_PRO_chain2. Changed it to 1\n",
      "  Final STD Null for Feature_ind/PSSM_TRP_chain2. Changed it to 1\n",
      "\n",
      "\n",
      "   Data Set Info:\n",
      "   Augmentation       : 0 rotations\n",
      "   Training set       : 1 conformations\n",
      "   Validation set     : 0 conformations\n",
      "   Test set           : 0 conformations\n",
      "   Number of channels : 64\n",
      "   Grid Size          : 35, 30, 30\n"
     ]
    }
   ],
   "source": [
    "data_set = DataSet(\n",
    "    'one_sample.hdf5',\n",
    "    chain1=\"M\",\n",
    "    chain2=\"P\",\n",
    "    process=False)\n",
    "\n",
    "state = torch.load(pretrained_model,  map_location='cpu')\n",
    "\n",
    "data_set.select_feature = state['select_feature']\n",
    "data_set.select_target = state['select_target']\n",
    "\n",
    "data_set.pair_chain_feature = state['pair_chain_feature']\n",
    "data_set.dict_filter = state['dict_filter']\n",
    "\n",
    "data_set.normalize_targets = state['normalize_targets']\n",
    "if data_set.normalize_targets:\n",
    "    data_set.target_min = state['target_min']\n",
    "    data_set.target_max = state['target_max']\n",
    "\n",
    "data_set.normalize_features = state['normalize_features']\n",
    "if data_set.normalize_features:\n",
    "    data_set.feature_mean = state['feature_mean']\n",
    "    data_set.feature_std = state['feature_std']\n",
    "\n",
    "data_set.transform = state['transform']\n",
    "data_set.proj2D = state['proj2D']\n",
    "data_set.target_ordering = state['target_ordering']\n",
    "data_set.clip_features = state['clip_features']\n",
    "data_set.clip_factor = state['clip_factor']\n",
    "data_set.mapfly = state['mapfly']\n",
    "data_set.grid_info = state['grid_info']\n",
    "\n",
    "data_set.process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 35, 30, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CnnClassificationBaseline(data_set.input_shape)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "if state['cuda']:\n",
    "    for paramname in list(state['state_dict'].keys()):\n",
    "        paramname_new = paramname.lstrip('module.')\n",
    "        if paramname != paramname_new:\n",
    "            state['state_dict'][paramname_new] = \\\n",
    "                state['state_dict'][paramname]\n",
    "            del state['state_dict'][paramname]\n",
    "\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.001)\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(range(data_set.__len__()))\n",
    "sampler = data_utils.sampler.SubsetRandomSampler(index)\n",
    "loader = data_utils.DataLoader(data_set, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 35, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(loader):\n",
    "    print(data['feature'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x29df3b070>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train(mode=False)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('one_sample.hdf5',), ('BA_105966',)]\n",
      "torch.Size([1, 64, 35, 30, 30])\n",
      "tensor([[0]])\n",
      "tensor([[ 1.9637, -1.9273]])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for d in loader:\n",
    "    inputs = d['feature']\n",
    "    targets = d['target']\n",
    "    mol = d['mol']\n",
    "    inputs, targets = Variable(inputs).float(), Variable(targets).float()\n",
    "    targets = targets.long()\n",
    "    print(mol)\n",
    "    print(inputs.shape)\n",
    "    print(targets)\n",
    "    outputs = net(inputs)\n",
    "    print(outputs)\n",
    "    targets = targets.view(-1)\n",
    "    print(targets)\n",
    "    # F.softmax(torch.FloatTensor(out), dim=1).data.numpy()[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 35, 30, 30)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_toplot = np.squeeze(np.array(inputs))\n",
    "inputs_toplot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 30, 30)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_vol = inputs_toplot[0, :, :, :]\n",
    "one_vol.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('deeprankcore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9044f9e9bb2984c6e66c1f9356a97652bc688d95c3fd9413d1ef7214abf67660"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
