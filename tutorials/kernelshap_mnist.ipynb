{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of explaining binary mnist with KernelSHAP <br>\n",
    "\n",
    "Function : Explaining binary mnist with KernelSHAP <br>\n",
    "Author : Team DIANNA <br>\n",
    "Contributor : <br>\n",
    "First Built : 2022.01.06 <br>\n",
    "Last Update : 2022.01.07 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangliu/miniconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import matplotlib.pyplot as plt\n",
    "from dianna.methods import KernelSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (binary MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of mnist:\n",
      "dimensions or training set (12665, 784)\n",
      "dimensions or training set label (12665,)\n",
      "dimensions or testing set (2115, 784)\n",
      "dimensions or testing set label (2115,)\n",
      "statistics of training set:\n",
      "Digits: 0 1\n",
      "labels: [0 1]\n",
      "Class distribution: [5923 6742]\n",
      "Labels of training set [0 1 1 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# load binary MNIST from local\n",
    "# load data\n",
    "fd = np.load(Path('binary-mnist.npz'))\n",
    "# training set\n",
    "train_X = fd['X_train'] / 255\n",
    "train_y = fd['y_train']\n",
    "# testing set\n",
    "test_X = fd['X_test'] / 255\n",
    "test_y = fd['y_test']\n",
    "fd.close()\n",
    "\n",
    "# dimensions of data\n",
    "print(\"dimensions of mnist:\")\n",
    "print(\"dimensions or training set\", train_X.shape)\n",
    "print(\"dimensions or training set label\", train_y.shape)\n",
    "print(\"dimensions or testing set\", test_X.shape)\n",
    "print(\"dimensions or testing set label\", test_y.shape)\n",
    "# statistics of training set\n",
    "print(\"statistics of training set:\")\n",
    "print(\"Digits: 0 1\")\n",
    "print(\"labels: {}\".format(np.unique(train_y)))\n",
    "print(\"Class distribution: {}\".format(np.bincount(train_y)))\n",
    "print(\"Labels of training set\", train_y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the input following the definition in pytorch (batch, channel, Height, Width)\n",
    "test_X = test_X.reshape(-1,28,28,1)\n",
    "# choose the image for explanation\n",
    "test_sample = test_X[1:2,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 15:14:07.336122: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-11 15:14:07.336690: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 15:14:07.337764: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "# Load saved onnx model\n",
    "onnx_model_path = \"../tests/test_data/mnist_model_tf.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BackendTFModule.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f8db5ae6fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BackendTFModule.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f8db5ae6fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 15:14:09.781168: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-11 15:14:09.784569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4380e407bde04c3e9b83afb9b7e7d6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Kernel SHAP to explain the network's predictions\n",
    "axes_labels = ('batch', 'height', 'width', 'channels')\n",
    "explainer = KernelSHAP()\n",
    "shap_values, segments_slic = explainer.explain_image(onnx_model_path, test_sample, nsamples=1000,\n",
    "                                      background=0, n_segments=200, sigma=0,\n",
    "                                      axes_labels = axes_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "predictions = prepare(onnx_model).run(np.expand_dims(test_sample.copy().astype(np.float32),\n",
    "                                      axis=0))[f'{output_node}']\n",
    "top_preds = np.argsort(-predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill each pixel with shap values based on the segmentation\n",
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the explanations\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\n",
    "inds = top_preds[0]\n",
    "axes[0].imshow(test_sample[0])\n",
    "axes[0].axis('off')\n",
    "# get the range for color bar\n",
    "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
    "for i in range(2):\n",
    "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
    "    axes[i+1].set_title(str(inds[i]))\n",
    "    axes[i+1].imshow(test_sample[0], alpha=0.15)\n",
    "    im = axes[i+1].imshow(m, vmin=-max_val, vmax=max_val)\n",
    "    axes[i+1].axis('off')\n",
    "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "cb.outline.set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
