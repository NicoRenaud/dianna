{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation for Pretrained Binary MNIST Model using KernelSHAP\n",
    "\n",
    "This notebook demonstrates how to apply KernelSHAP algorithms on pretrained binary MNIST model using a hand-written digit image and visualizes the attributions for each pixel/super-pixel by displaying them on the image. <br>\n",
    "\n",
    "SHapley Additive exPlanations, in short, SHAP, is a model-agnostic explainable AI approach which is used to decrypt the black-box models through estimating the Shapley values.<br>\n",
    "\n",
    "KernelSHAP is a variant of SHAP. It is a method that uses the LIME framework to compute Shapley Values.<br>\n",
    "\n",
    "More details about this method can be found in the paper https://arxiv.org/abs/1705.07874."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # disable warnings relateds to versions of tf\n",
    "import numpy as np\n",
    "import dianna\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Loading the model and the dataset\n",
    "Loads pretrained binary MNIST model and the image to be explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load saved binary MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = np.load('./data/binary-mnist.npz')\n",
    "# load testing data and the related labels\n",
    "X_test = data['X_test'].astype(np.float32).reshape([-1, 28, 28, 1]) / 255\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained binary MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:06:54.728270: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-20 14:06:54.728544: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-20 14:06:54.728952: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Load saved onnx model\n",
    "onnx_model_path = \"./models/mnist_model_tf.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "# get the output node\n",
    "output_node = prepare(onnx_model, gen_tensor_dict=True).outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print class and image of a single instance in the test data for preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BackendTFModule.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4affb63670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BackendTFModule.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4affb63670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:06:55.422769: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-20 14:06:55.423958: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: digit 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a5cf994f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class name\n",
    "class_name = ['digit 0', 'digit 1']\n",
    "# instance index\n",
    "i_instance = 1\n",
    "# expand the dimension of instance for testing\n",
    "test_sample = np.expand_dims(X_test[i_instance].copy().astype(np.float32), axis=0)\n",
    "# model predictions\n",
    "predictions = prepare(onnx_model).run(test_sample)[f'{output_node}']\n",
    "pred_class = class_name[np.argmax(predictions)]\n",
    "print(\"The predicted class is:\", pred_class)\n",
    "plt.imshow(X_test[i_instance][:,:,0])  # 0 for channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Compute Shapley values and visualize the attributions\n",
    "Approximate Shapley values using KernelSHAP and visualize the attributions on the image. <br>\n",
    "\n",
    "KernelSHAP approximate Shapley values in the LIME framework.\n",
    "The user need to specified the number of times to re-evaluate the model when explaining each prediction (`nsamples`). A binary mask need to be applied to the image to represent if an image region is hidden. It requires the background color for the masked image, which can be specified by `background`.<br>\n",
    "\n",
    "Performing KernelSHAP on each pixel is inefficient. It is always a good practice to segment the input image and perform computations on the obtained superpixels. This requires the user to specify some keyword arguments related to the segmentation, like the (approximate) number of labels in the segmented output image (`n_segments`), and width of Gaussian smoothing kernel for pre-processing for each dimension of the image (`sigma`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5b5be599e149849805ec7ab5355739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use KernelSHAP to explain the network's predictions\n",
    "shap_values, segments_slic = dianna.explain_image(onnx_model_path, test_sample,\n",
    "                                                  method=\"KernelSHAP\", nsamples=1000,\n",
    "                                                  background=0, n_segments=200, sigma=0,\n",
    "                                                  axes_labels=('batch','height','width','channels'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to fill each pixel with shap values based on the segmentation. <br>\n",
    "This function is used to make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill each pixel with SHAP values \n",
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Shapley scores on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAD/CAYAAAD17AypAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUc0lEQVR4nO3de5BcZZnH8d8zk8vkAiThlkAiCSsghlogobIsCIpIyFIoZJWbUAsKcpMtrV2XhQVZcVEUa72tqFALBVIUIAICq+5yWVIotyAICSQkRC5LEiCBQBISEpKZd//oE9LT5+3h7enpPt3PfD9VXTP9nue8/XbemslvTp9zXgshCAAAwLOOogcAAADQaAQeAADgHoEHAAC4R+ABAADuEXgAAIB7BB4AAOAegQcAALhH4AHQNGY2zszuMLN1ZvaymX2+6DEBRTKz88zsj2a20cyuK3o8ng0pegAABpUrJb0naWdJ+0n6jZk9HUJ4ttBRAcVZLukySUdKGlHwWFwz7rQMoBnMbJSktyTtE0JYnLXdIGlZCOGCQgcHFMzMLpM0MYRwWtFj8YqPtAA0y56SureEnczTkqYWNB4AgwiBB0CzjJa0uqJttaRtChgLgEGGwAOgWd6RtG1F27aS1hYwFgCDDIEHQLMsljTEzPYoa9tXEicsA2g4Ag+ApgghrJN0u6RvmtkoMztY0jGSbih2ZEBxzGyImXVJ6pTUaWZdZsYV1A1A4AHQTOeqdOntCkk3STqHS9IxyF0s6V1JF0g6Jfv+4kJH5BSXpQMAAPc4wgMAANwj8AAAAPcIPAAAwD0CDwAAcI/AAwAA3OvXtf5HdBzHpV1oqHt7brWix1CLKT/6d34m0FAvfuUf+ZkAytT6M8ERHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHoEHAAC4R+ABAADuEXgAAIB7BB4AAOBev+60DAAxPaO7k+o63uls8EjaQ09XT9FDQIMNXZt2M+BN23Bjaknq3NC4G4pzhAcAALhH4AEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHoEHAAC4R+ABAADusbREHTrHbJdrW/ST3XNtzx32n9H9L14xPdc2/+Q9o7XdCxbXODo0U8/ItCUVJKmzhmUVQoP+JKllvB3r08fLkhG16djg92/OIevSlwjYPLqGZRUatAJDTeMdlT4IloyoTXdX4/69/P60AQAAZAg8AADAPQIPAABwj8ADAADc46TlOvRMmZhrm/+Jq3Jtm6qcg3XZTk/k2vadfVC0dhInLQMA0G8c4QEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7nGVVoIhk/JXY0nSlKuXNHkkaFW1LL/QqOUialHTeMduSq4dtd27SXXrX9o2uU+0p1qWX2jUchG1qGW8w1el/xAPW51Wt3ZKT3KfLaGWOUtftaOhWuBXLwAAQGMReAAAgHsEHgAA4B6BBwAAuMdJyxX+75L80g7TZy2I1l4x4fcD/vqjD1oZbX/l6/lx7TBvc7R2xJ1zB3RMAAC0O47wAAAA9wg8AADAPQIPAABwj8ADAADcI/AAAAD3uEqrwryz/iPXtil0N+315+x7Y3zDvvmmO9ZNiJZeu/bYXNuQ/32ijlHBm2ET1yXXfmjcW8m1S+bFl2FplvF7r0iufW3hTg0cCdrNqFfS//4fsTJ9XYU3phW7bsbYZ9PXdXhrag1jbZHlImrBER4AAOAegQcAALhH4AEAAO4ReAAAgHuD9qTloXPiJ/wOtc6mjeFP7/Xk2l7atGO0dvaoVbm240fHT9A8/oarc21H7zq9xtEBAOAHR3gAAIB7BB4AAOAegQcAALhH4AEAAO4ReAAAgHuD4iqtd4+dkWv7woRbo7WxZSTqXVpin/vPjrbveP/wXNvw1fHXuvAT+Ww6/7gfJ49h6YUHRdsnXv5wch/w49DdljSk3yUqdmmJlW+PTq7dfs83k2vfXLx9f4aDNjJ28eYG9VzscYWNY9PXgBjzXHq/b3+k2CUz+oMjPAAAwD0CDwAAcI/AAwAA3CPwAAAA91ydtNw5da9o+2Xfzy+1cMCw96r1kvx6d6zLL09x8QOfzbXtfX78TLDuNWuSX2uv5/fMtc39TFe0dsbwDbm2351zRbR2Ztf5ubbJ334iWhs2buxriAAAtCyO8AAAAPcIPAAAwD0CDwAAcI/AAwAA3CPwAAAA91xdpdUzLP52ql+RleaLL8+Ktq89YUSubc+lc3Nt9S1MkfWxYHGu7dzr4ktW/PGsH+baJnTmxypJT56er/3s7adGa8PTC6sPEG3lovH3Jtd+67UjGjiS4szdP768TMxfLI7/rMGPUQ89n1y77uA9GjiS4uxw1SPJtW//4MAGjqQxOMIDAADcI/AAAAD3CDwAAMA9Ag8AAHDP1UnLA+FfXj8g17bmjO2jtd1L009ya4TJt70Rbf/6sfmTyb4z/vFGDwcAgJbFER4AAOAegQcAALhH4AEAAO4ReAAAgHuD4qTlodaZXDtvWoi0FntyclVm0eYhHT25tlr+DZZfGm8ff2xyFyhAT1d+3qupduftmPse2rc/wynE8OGbk2tf3PROcm0Yl363dls1LLkWjdW5If47MqZ79Zrk2qWHt8+xgs6NNdRuPy65dvib6f8GG7dP/93USO0zawAAAP1E4AEAAO4ReAAAgHsEHgAA4B6BBwAAuOfqKq1F54yMtm8K3U0eSXO89LfxJS9+tePcXNumEL9KK/Zvs8u/xl+vNc6zBwCgdhzhAQAA7hF4AACAewQeAADgHoEHAAC45+qk5YsPubvoIdRtyKSJ0fa103fJtf38Cz+t+/XmbuzKtdl76bfnR+v4+0PuS6499aVPNXAkxZn5oeeSa6cMHZ1cy3IR7Wny3euTa9fNPqCBIynO2EXpy6J0v7kqubZVlouoBUd4AACAewQeAADgHoEHAAC4R+ABAADuEXgAAIB7rq7S8mDBpeOj7c/O/Eld/d72zg7R9p997bhcW9fC/NIUAAC0M47wAAAA9wg8AADAPQIPAABwj8ADAADc46TlAg2dMyHXdvmE2xryWtctOyja3nU3Jyh7saFnaHLthK7VDRzJwDryY08l11640++Ta6c+cmY/RoN2EjrT/6Yf+k53DT0X+1/npPvSx9r1h4XJtcu/Gv9/Io6lJQAAAFoOgQcAALhH4AEAAO4ReAAAgHsEHgAA4J6rq7Q6LX7W+FDrTO5jzecPTK699JvX5NoOG7Ehef/YuDaFamffp7+HmPDJZXXtDwBAO+MIDwAAcI/AAwAA3CPwAAAA9wg8AADAPVcnLX/nls9F248//YfJfTz4vStzbdVPJM7bFJJLq+xfy+3N4/a5/+xc2x56su5+MTB6utJvyd6xIf1vkmueTr8t/NUH/SK59teakVzbCI8sn5xc+0/ds5Jr3102OrnWkivRH50b0v+Fu7vSf8kuP2REcu1uv3w1uVbauYbagbd6cvoyMj1HTE2uXbdrnf+BtTiO8AAAAPcIPAAAwD0CDwAAcI/AAwAA3CPwAAAA91xdpbX7LW9E2+ee0pVrmzE8fQmIZpq7MT9WSbr6tY/n2t46d3y09iMvLsm11X/tFwAA7YsjPAAAwD0CDwAAcI/AAwAA3CPwAAAA91ydtNy9YHG0/ZJ/OCPX9sqn47f3X/w3Vw3omGp17rX5ZSEkadK3Ho60vtXYwaAhalkuohbh7WHJtWfe9aWGjCHVkF3WJ9eueWFMcu2DNdSyXETrqGW5iFq8Nya930VfLna5iJHL0n8vrPlw+vI0az5cy+8blpYAAABoawQeAADgHoEHAAC4R+ABAADuEXgAAIB7rq7SqmbEnXNzbXveGa899KQv59qGnvZ6tPa/p96Sa5v5zIm5tp7rdoruHyKXiUx+amW0lqUhAADoP47wAAAA9wg8AADAPQIPAABwj8ADAADcGxQnLddi25sezTfeFK+drRm5tlF6IVIZa4vj5GT0l21un8USNi8fWfQQatI5/t3k2u7XRjRwJKhFz9D2WSph/a7py0W0gpGvph8vWT+hNd4bR3gAAIB7BB4AAOAegQcAALhH4AEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHktLABiUQmf6sgMsF4HBoJblaVpluYhacIQHAAC4R+ABAADuEXgAAIB7BB4AAOAegQcAALhH4AEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7lkI6bdXBwAAaEcc4QEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHoEHAAC4R+ABAADuEXgAAIB7BB4AAOAegQcAALhH4AEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHoEHAAC4R+ABAADuEXgAAIB7BB4AAOAegQcAALhH4AEAAO4ReAAAgHsEHgAA4B6BBwAAuEfgAQAA7hF4AACAewQeAADgHoEHAAC4N6SvjUd0HBckSbY1F1mHqbyt8rnef25l+3T0bss9L6ut1k+1faM1lfuW5bpq/VbbV1J4f1uV18u+hvIxVanN9RXbZhXtlX1JChU1W/aJ9V/Zb+W+W5+Xjakjvi33ugk1sf63vqca9qn6OhXPe7VVe+8D03/V2sq6lH4Tavvap5ba/uyTrw199tHntsp9y+XGEKr2X9lf1X3LttkH9hvbJ/T5PNavvf+1r31C7yFU2bej7H18UI2V1Xao75roPlu2KV7bEaut2CfX3kf/W2t68rVVajpzffTk+u9UvN+t+8b2qazt6fU6vdq2jKXidSqfR/tVT+++Yv2r93vd2kdPr+ex99RZURPr//1x5vbJz9n7463YtuV5p8rnV71r33/dLe3Wq720bUubVdRYxfate23d1tFrW8f4xbHfKrnXBAAAcInAAwAA3CPwAAAA9wg8AADAPQIPAABwj8ADAADcI/AAAAD3CDwAAMA9CyF8cFWLM7MzQwhXFz0ODDzm1ifm1S/m1icP8+rlCM+ZRQ8ADcPc+sS8+sXc+tT28+ol8AAAAFRF4AEAAO55CTxt/bki+sTc+sS8+sXc+tT28+ripGUAAIC+eDnCAwAAUFXbBB4zG2dm95rZ89nXsVXqZpnZIjNbYmYXlLV/z8yeM7N5ZnaHmY1p2uBR1QDM63Fm9qyZ9ZjZAc0bOaqpNldl283Mfpxtn2dm01L3RXHqnNdrzWyFmT3T3FEjRX/n1swmmdkDZrYw+z38leaPvgYhhLZ4SLpC0gXZ9xdI+m6kplPSnyXtLmmYpKclfTTbNlPSkOz778b259GW87q3pL0kzZF0QNHvZ7A/+pqrspqjJP1Okkk6UNJjqfvyaL95zbYdKmmapGeKfi88Bm5uJU2QNC37fhtJi1v5Z7ZtjvBIOkbS9dn310s6NlIzQ9KSEMILIYT3JN2c7acQwj0hhM1Z3aOSJjZ2uEhU77wuDCEsasZAkaTqXJU5RtIvQsmjksaY2YTEfVGMeuZVIYQHJa1q6oiRqt9zG0J4NYTwpCSFENZKWihp12YOvhbtFHh2DiG8KknZ150iNbtKeqXs+VLF//G/qFJaRfEGcl5RvJS5qlbDPLeueuYVrW1A5tbMJkvaX9JjAz/EgTGk6AGUM7P7JI2PbLootYtIW6/L0MzsIkmbJd1Y2+jQX82YV7SMlLmqVsM8t6565hWtre65NbPRkm6T9NUQwpoBHNuAaqnAE0L4VLVtZvb6lkNo2WHSFZGypZImlT2fKGl5WR+nSjpa0uEh+9ARjdfoeUVLSZmrajXDEvZFMeqZV7S2uubWzIaqFHZuDCHc3sBx1q2dPtK6S9Kp2fenSrozUvO4pD3MbIqZDZN0YrafzGyWpH+W9JkQwvomjBdp6ppXtJyUubpL0t9lV34cKGl19nEm89y66plXtLZ+z62ZmaRrJC0MIXy/ucPuh6LPmk59SNpe0v2Sns++jsvad5H027K6o1Q6U/zPki4qa1+i0meQT2WPnxf9nngMyLzOVumvj42SXpf0P0W/p8H+iM2VpLMlnZ19b5KuzLbPV9nVddXmmUfxjzrn9SZJr0ralP28nl70++FR/9xK+phKH23NK/u/9aii30+1B3daBgAA7rXTR1oAAAD9QuABAADuEXgAAIB7BB4AAOAegQcAALhH4AEgqXQX8mzF43lm9pSZ/VXWPqd8JXozm1y56rWZ/cjMlplZR1nbaWa2MutrgZl9aQDG+Akz+696+wEw+LTUnZYBFMPM/lqlu5BPCyFsNLMdVLrzccq+HSrdD+kVlVbFnlO2+ZYQwnlmtpOkZ83srhDC6wM7egD4YBzhASBJEyS9EULYKEkhhDdCCKnLAhwm6RlJP5N0UqwghLBCpZuW7VbebmaPmdnUsudzzGy6mc0ws4fN7E/Z170q+zSzb5jZ18qeP5MtYCgzO8XM5mZHl64ys87E9wLAKQIPAEm6R9IkM1tsZj81s49XbL8xCw9PSfptxbaTVLqT7h2Sjs7W1unFzHaXtLtKdzwvd7Ok47OaCZJ2CSE8Iek5SYeGEPaXdImkb6e+ETPbW9IJkg4OIewnqVvSyan7A/CJwANAIYR3JE2XdKaklZJuMbPTykpODiHslwWIo7Y0ZmvvHCXp16G0SvJjkmaW7XdCFpJuknRWCGFVxUv/UtJx2ffHS7o1+347Sbdm5wr9QNJUpTs8ey+PZ699uEphC8Agxjk8ACRJIYRulc6/mWNm81VazPW6D9htlkrhZH5pHUGNlLRe0m+y7beEEM7r4zWXmdmbZvaXKh2VOSvb9G+SHgghzM4+ppoT2X2zev/R1pV9NUnXhxAu/ICxAxhEOMIDQGa2l5ntUda0n6SXE3Y9SdIZIYTJIYTJkqZImmlmI2t4+ZslnS9puxDC/KxtO0nLsu9Pq7LfS5KmZeOflr22VFqE9nPZidIys3Fmtlu0BwCDBoEHgCSNlnR9dvn4PEkflfSNvnbIQs2R2no0RyGEdZL+IOnTNbz2rySdqNLHW1tcIelyM3tIUrUTjm+TNC772OoclVZ7VghhgaSLJd2TvZd7VTopG8AgxmrpAADAPY7wAAAA9wg8AADAPQIPAABwj8ADAADcI/AAAAD3CDwAAMA9Ag8AAHCPwAMAANz7fybEc0K1K+9ZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the index of predictions\n",
    "top_preds = np.argsort(-predictions)\n",
    "inds = top_preds[0]\n",
    "# Visualize the explanations\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\n",
    "axes[0].imshow(test_sample[0])\n",
    "axes[0].axis('off')\n",
    "# get the range for color bar\n",
    "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
    "# plot the test image and the attributions on the image for each class\n",
    "for i in range(2):\n",
    "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
    "    axes[i+1].set_title(str(inds[i]))\n",
    "    axes[i+1].imshow(test_sample[0], alpha=0.15)\n",
    "    im = axes[i+1].imshow(m, vmin=-max_val, vmax=max_val)\n",
    "    axes[i+1].axis('off')\n",
    "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "cb.outline.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Conclusions\n",
    "The Shapley scores are estimated using KernelSHAP for models used to categorize the binary MNIST. The example here shows that the KernelSHAP method evaluates the importance of each segmentations/super pixels to the classification and the results are reasonable based on human visual preception of the chosen testing hand-written digit image."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
