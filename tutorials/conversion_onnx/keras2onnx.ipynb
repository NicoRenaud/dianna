{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras to ONNX conversion\n",
    "This notebook shows how to convert your trained Keras model to ONNX, the generic format supported by DIANNA. <br>\n",
    "\n",
    "The conversion is complete with the tf2onnx Python package, which supports both the SavedModel format and the older HDF5 (.h5 or .keras) format. It can convert multi-backend keras as well as tf.keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "# In addition to these imports, this notebook\n",
    "# depends on tf2onnx. It is used from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and initialize built-in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 14:08:10.935671: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-01 14:08:10.936024: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-01 14:08:10.941962: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102973440/102967424 [==============================] - 18s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "model = keras.applications.resnet50.ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model on some random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 14:08:31.066266: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-01 14:08:31.071050: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2304005000 Hz\n"
     ]
    }
   ],
   "source": [
    "input_shape = [1] + model.inputs[0].shape[1:]  # input shape without a 1 for batch size, instead of None\n",
    "input_data = np.random.normal(size=input_shape).astype(np.float32)\n",
    "pred = model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save keras model to SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 14:08:57.232998: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/resnet_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "savedmodel_dir = 'resnet_savedmodel'\n",
    "tf.saved_model.save(model, savedmodel_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yangliu/miniconda3/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-02-01 14:10:56,018 - INFO - Signatures found in model: [serving_default].\n",
      "2022-02-01 14:10:56,019 - INFO - Output names: ['predictions']\n",
      "WARNING:tensorflow:From /home/yangliu/miniconda3/lib/python3.8/site-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-02-01 14:10:58,785 - WARNING - From /home/yangliu/miniconda3/lib/python3.8/site-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-02-01 14:10:59,963 - INFO - Using tensorflow=2.4.1, onnx=1.9.0, tf2onnx=1.9.3/1190aa\n",
      "2022-02-01 14:10:59,963 - INFO - Using opset <onnx, 9>\n",
      "2022-02-01 14:11:03,452 - INFO - Computed 0 values for constant folding\n",
      "2022-02-01 14:11:05,876 - INFO - Optimizing ONNX model\n",
      "2022-02-01 14:11:11,212 - INFO - After optimization: Add -1 (18->17), BatchNormalization -53 (53->0), Const -162 (270->108), GlobalAveragePool +1 (0->1), Identity -57 (57->0), ReduceMean -1 (1->0), Squeeze +1 (0->1), Transpose -213 (214->1)\n",
      "2022-02-01 14:11:11,764 - INFO - \n",
      "2022-02-01 14:11:11,764 - INFO - Successfully converted TensorFlow model ../models/resnet_savedmodel to ONNX\n",
      "2022-02-01 14:11:11,765 - INFO - Model inputs: ['input_1']\n",
      "2022-02-01 14:11:11,765 - INFO - Model outputs: ['predictions']\n",
      "2022-02-01 14:11:11,765 - INFO - ONNX model is saved at ../models/resnet_savedmodel.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_savedmodel = 'resnet_savedmodel.onnx'\n",
    "!python -m tf2onnx.convert --saved-model {savedmodel_dir} --output {onnx_savedmodel} --signature_def serving_default --tag serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate ONNX models and compare to keras model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify the ONNX model is valid\n",
    "onnx_model = onnx.load(onnx_savedmodel)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# get ONNX predictions\n",
    "sess = ort.InferenceSession(onnx_savedmodel)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "onnx_input = {input_name: input_data}\n",
    "pred_onnx = sess.run([output_name], onnx_input)[0]\n",
    "\n",
    "print(np.allclose(pred_onnx, pred, atol=1e-5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7604e8ec5f09e490e10161e37a4725039efd3ab703d81b1b8a1e00d6741866c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
